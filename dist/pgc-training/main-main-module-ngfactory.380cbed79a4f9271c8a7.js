(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{o1NI:function(n,e,a){"use strict";a.r(e);var t=a("CcnG"),l=function(){return function(){}}(),i=a("pMnS"),s=a("LOpI"),o=t.jb({encapsulation:2,styles:[],data:{}});function r(n){return t.wb(0,[t.sb(null,0)],null,null)}var u=function(){function n(){}return n.prototype.ngOnInit=function(){},n}(),c=t.jb({encapsulation:0,styles:[["markdown[_ngcontent-%COMP%]     p{margin-bottom:.625rem}markdown[_ngcontent-%COMP%]     h3{margin-top:1rem}markdown[_ngcontent-%COMP%]     h2{margin-top:2rem;border-bottom:1px solid #c9c9c9;padding-bottom:.5rem}markdown[_ngcontent-%COMP%]     table{width:100%;max-width:100%;margin-bottom:20px;border-spacing:0;border-collapse:collapse}markdown[_ngcontent-%COMP%]     table>thead>tr>th{vertical-align:bottom;border-bottom:2px solid #ddd}markdown[_ngcontent-%COMP%]     table>thead:first-child>tr:first-child>th{border-top:0}markdown[_ngcontent-%COMP%]     table>tfoot>tr>td, markdown[_ngcontent-%COMP%]     table>tfoot>tr>th, markdown[_ngcontent-%COMP%]     table>thead>tr>td, markdown[_ngcontent-%COMP%]     table>thead>tr>th{line-height:1.5}markdown[_ngcontent-%COMP%]     table>tbody>tr>td, markdown[_ngcontent-%COMP%]     table>tbody>tr>th, markdown[_ngcontent-%COMP%]     table>tfoot>tr>td, markdown[_ngcontent-%COMP%]     table>tfoot>tr>th, markdown[_ngcontent-%COMP%]     table>thead>tr>td, markdown[_ngcontent-%COMP%]     table>thead>tr>th{line-height:1.5;padding:5px;vertical-align:top;border-top:1px solid #ddd}"]],data:{}});function d(n){return t.wb(0,[(n()(),t.lb(0,0,null,null,2,"markdown",[["class","markdown"]],null,null,null,r,o)),t.kb(1,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n## 1. Quality Control\n"])),(n()(),t.lb(3,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(4,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 1.1 Setting Up\n\nCopy all data files from */home/training/data/workshop* to your home directory. \n\n```bash\ncd ~\ncp -r /home/training/data/workshop data\nmkdir qc\n```\n"])),(n()(),t.lb(6,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(7,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 1.2 Running Quality Control\n\n#### Tool: Fastp\n\nQuality control and preprocessing of sequencing data are critical to obtaining high-quality and high-confidence variants in downstream data analysis. Data can suffer from adapter contamination, base content biases and overrepresented sequences. Even worse, library preparation and sequencing steps always involve errors and can cause inaccurate representations of original nucleic acid sequences.\n\nIn the past, multiple tools were employed for Fastq data quality control and preprocessing. A typical combination was the use of [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) for quality control, [Cutadapt](https://cutadapt.readthedocs.io/en/stable/guide.html)  for adapter trimming and [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) for read pruning and filtering. September this year, a tool called [Fastp](https://github.com/OpenGene/fastp) was created that does all these steps, and allows multi-threading which makes the processing of reads significantly faster. \n\n```bash\nfastp --in1 ~/data/reads/reads1.fq --out1 ~/qc/reads1_fastp.fq \\\n    --in2 ~/data/reads/reads2.fq --out2 ~/qc/reads2_fastp.fq\nmv fastp.* ~/qc\n```\n\nOpen the *.html* files using a browser.\n\n**Guide Questions:**\n\n* Is the initial data quality good enough for downstream analysis?\n* Was there adapter contamination remaining in the raw sequence reads?\n* How many sequence reads are there initially?\n* How many reads are left after filtering?\n* How many reads (and what percent of the total number of reads) were filtered out after quality control?\n\n"])),(n()(),t.lb(9,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(10,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n## 2. Genome Assembly\n\n"])),(n()(),t.lb(12,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(13,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 2.1 Assembly\n\n#### Tool: SPAdes\n\n[SPAdes](http://cab.spbu.ru/software/spades/) is a short-read assembler specifically designed for bacterial genomes, and has become very popular in recent years because of its performance and ease of use. It has a reputation for producing good assemblies, and can be run using one simple command.\n\n```bash\nspades.py -1 ~/qc/reads1_fastp.fq -2 ~/qc/reads2_fastp.fq -o ~/assembly -t 4 \\\n    -m 20 --careful\n```\n\nSPAdes creates two assemblies, **contigs.fasta** and **scaffolds.fasta**. They will be found in the *__~/assembly__* directory.\n"])),(n()(),t.lb(15,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(16,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 2.2 Quality Assessment\n\n#### Tool: QUAST\n\nNow that you have generated several assemblies, you need to assess their quality. We can do this with a tool called [QUAST](http://bioinf.spbau.ru/quast), which simply analyzes an assembly, calculates metrics such as the assembly length and number of contigs, and generates a report.\n\nThe following commands will take the assemblies you generated using SPAdes, and generate reports located in subdirectories of *__~/assessment__*.\n\n```bash\nquast.py -o ~/assessment/contigs -t 4 ~/assembly/contigs.fasta\nquast.py -o ~/assessment/scaffolds -t 4 ~/assembly/scaffolds.fasta\n```\n\n**Guide Questions:**\n\n1. What is the best assembly based on total assembly length?\n2. What is the best assembly based on the number of contigs?\n3. What is the best assembly based on the length of the largest contig?\n4. What is the best assembly based on N50?\n"])),(n()(),t.lb(18,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(19,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 2.3 Mapping Reads to Assembly\n\n#### Tools: Bowtie 2, SAMtools\n\nAt this point, your assembly is complete - you can move on to other steps like genome annotation. But for instruction purposes, it helps to visualize the assembly you created. To do this, first we'll map (i.e. align) the filtered reads to the SPAdes assembly you created, using a suite of tools called [Bowtie 2](http://bowtie-bio.sourceforge.net/bowtie2/index.shtml). The tool `bowtie2-build` indexes the reference sequence, while `bowtie2` performs the actual alignment.\n\nThe output will be a file called **assembly.sam**, which is in the SAM (Sequence Alignment Map) format. Create and go into the directory *__~/assembly/mapping__* before running the Bowtie 2 commands. This is where the output will be located.\n\n```bash\nmkdir ~/assembly/mapping\ncd ~/assembly/mapping\nbowtie2-build --threads 4 ~/assembly/scaffolds.fasta assembly\nbowtie2 -p 4 -x assembly -1 ~/qc/reads1_fastp.fq -2 ~/qc/reads2_fastp.fq -S assembly.sam\n```\n\nNext, we'll pre-process the alignment for visualization, using the tool suite [SAMtools](http://www.htslib.org/). We'll be using the following utilities:\n\nTool | What it does\n---- | ------------\n`samtools view` | Convert to BAM (Binary Alignment Map) format\n`samtools sort` | Sort BAM file based on position in alignment\n`samtools index` | Create an index (`.bai` file) for fast look-up \n\nHere are the commands (make sure you're still in *__~/assembly/mapping__*):\n\n```bash\nsamtools view -b assembly.sam -o assembly.bam\nsamtools sort assembly.bam -o assembly_sorted.bam\nsamtools index assembly_sorted.bam\n```\n"])),(n()(),t.lb(21,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(22,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 2.4 Visualization\n\n#### Tool: Tablet\n\nNow that we have aligned the reads to the assembly and pre-processed them, we can proceed to visualization. To see the alignment, we will use a lightweight, high-performance graphical viewer called [Tablet](https://ics.hutton.ac.uk/tablet/). We can start Tablet by invoking a simple command:\n\n```bash\ntablet\n```\n\nThen simply load the aligned reads, along with the assembled genome as reference:\n\n* Tablet -> Open Assembly\n    + Primary assembly file: `~/assembly/mapping/assembly_sorted.bam`\n    + Reference/consensus file: `~/assembly/scaffolds.fasta`\n    + Click \"Open\"\n\n#### Tool: Bandage\n\nA different way of examining your assembly is by visualizing the assembly graph, which you can do with another graphical viewer called [Bandage](https://rrwick.github.io/Bandage/). Many assemblers automatically produce a file containing the assembly graph; in SPAdes this will be **assembly_graph.fastg**. Just start Bandage and load the file of your choice.\n\n```bash\nBandage\n```\n\n* Bandage -> File -> Load Graph -> `~/assembly/assembly_graph.fastg`\n* Click on 'Draw graph'\n\n**Guide Question:**\n\n1. SPAdes creates assemblies for different k-mers (look for the directories named  *__K21__*, *__K55__*, etc. in *__~/assembly__*). Based on visual appearance, what value of *k* resulted in the best de Bruijn graph?\n\nSee [this site](https://github.com/rrwick/Bandage/wiki/Getting-started) for instructions on how to rotate and manipulate the assembly graph. Try experimenting with the different visualization features of the software. \n"])),(n()(),t.lb(24,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(25,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n## 3. Genome Annotation\n"])),(n()(),t.lb(27,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(28,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 3.1 Setting Up\n\nFirst, we will create the directory *__annot__* inside our home directory. We will then move to this directory. This will be our new work directory.\n\n```bash\nmkdir ~/annot\ncd ~/annot\n```\n"])),(n()(),t.lb(30,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(31,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 3.2 Running Annotation\n\n#### Tool: Prokka\n\nTo annotate our genome assembly, we will use the tool [Prokka](http://www.vicbioinformatics.com/software.prokka.shtml). This tool is designed to coordinate a number of pre-existing tools in order to reliably predict genomic features for bacterial, archaeal, and viral sequences.\n\nFor this exercise, we will use the assembly generated using the tool SPAdes. The output files, all of which will contain the prefix **prokka**, will be placed inside the directory *__~/annot/prokka__*. The procedure will use a maximum of four (4) computing cores.     \n\n```bash\nprokka --prefix prokka --cpus 4 ~/assembly/scaffolds.fasta\n\n```\n\n**Workflow Description:**\n\nThe Prokka workflow by default will run the following tools:\n\n1. [Aragorn](http://mbio-serv2.mbioekol.lu.se/ARAGORN/) to predict tRNAs;\n2. [Barnap](https://github.com/tseemann/barrnap) to predict rRNAs;\n3. [Prodigal](https://github.com/hyattpd/Prodigal) to predict protein coding sequences;\n4. [Blast](ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/) for sequence similarity search; and\n5. [Hmmer](http://hmmer.org/) for sequence motif search.\n\n**Expected Outputs:**\n\nAfter running Prokka, the following output files will be generated:\n\n\nOutput File | Content Description\n----------- | -------------------\n`*.fna`       | FASTA file of original input contigs (nucleotide)\n`*.faa`       | FASTA file of translated coding genes (protein) \n`*.ffn`       | FASTA file of all genomic features (nucleotide) \n`*.fsa`       | Contig sequences for submission (nucleotide)\n`*.tbl`       | Feature table for submission \n`*.sqn`       | Sequin editable file for submission\n`*.gbk`       | Genbank file containing sequences and annotations \n`*.gff`       | GFF v3 file containing sequences and annotations \n`*.log`     \t| Log file of Prokka processing output \n`*.txt` \t    | Annotation summary statistics \n\n"])),(n()(),t.lb(33,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(34,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 3.3 Visualization\n\n#### Tool: Artemis\n\nWe can view the annotation by loading the **prokka.gff** output into the tool [Artemis](https://www.sanger.ac.uk/science/tools/artemis). We can start Artemis by invoking the following command:\n\n```bash\nart\n```\n\nA window will appear and we will open the input annotation file from there.\n\n* File -> Open ... -> `~/annot/prokka/prokka.gff`\n\nTo learn more about how to explore annotations in Artemis, you can follow [this link](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.99.6409&rep=rep1&type=pdf).\n\n**Guide Questions:**\n\n1. How many protein coding sequences were predicted?\n2. How many rRNA genes were predicted?\n3. How many tRNA genes were predicted?\n4. Do you think the assemblies are correct based on the annotated genes? Why or why not? How can you check if the annotations are correct?\n\n"])),(n()(),t.lb(36,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(37,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n## 4. Mapping Short Reads to Reference Genome\n"])),(n()(),t.lb(39,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(40,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 4.1 Setting Up\n\nFirst, we will create a new directory in our home directory called *__mapping__*. Move here, this will be our new work directory.\n\n```bash\nmkdir ~/mapping\ncd ~/mapping\n```\n"])),(n()(),t.lb(42,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(43,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 4.2 Read Mapping\n\n#### Tools: BWA, SAMtools\n\nAs we did during the de novo assembly exercise, we will be using a read mapping software package to index a reference sequence and map our reads. But this time, instead of using Bowtie 2, we will be using [BWA](http://bio-bwa.sourceforge.net/), and our reference will be *__~/data/ref/ecoli.fasta__*. As before, there is an indexing step and a read mapping step.\n\n```bash\nbwa index ~/data/ref/ecoli.fasta    #Index files will be created in ~/data/ref/\nbwa mem ~/data/ref/ecoli.fasta ~/qc/reads1_fastp.fq ~/qc/reads2_fastp.fq \\\n    > ~/mapping/alignment.sam\n```\n\nBefore we proceed, take a look inside the resulting SAM file. Examine its headers and its FLAG values.\n\n```bash\nless -S ~/mapping/alignment.sam\n```\n\n**Guide Questions:**\n\n1. How long is the reference genome?\n2. What SAM flags are you observing? Are these what you'd expect in a good alignment?\n\nOnce again, we will pre-process our alignment using SAMtools, following the same steps as we did before.\n\n```bash\nsamtools view -b alignment.sam -o alignment.bam\nsamtools sort alignment.bam -o alignment_sorted.bam\nsamtools index alignment_sorted.bam\n```\n\n"])),(n()(),t.lb(45,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(46,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,['\n### 4.3 Visualization\n\n#### Tool: Tablet\n\nNow that we have aligned the reads to the reference and pre-processed them, we can again proceed to visualization, using  [Tablet](https://ics.hutton.ac.uk/tablet/). We can start Tablet by invoking a simple command:\n\n```bash\ntablet\n```\n\nThen simply load the aligned reads, along with the referece genome:\n\n* Tablet -> Open Assembly\n    + Primary assembly file: `~/mapping/alignment_sorted.bam`\n    + Reference/consensus file: `~/data/ref/ecoli.fasta`\n    + Click "Open"\n'])),(n()(),t.lb(48,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(49,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n## 5. Variant Calling \n"])),(n()(),t.lb(51,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(52,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 5.1 Setting Up\n\nFirst, we will create the directory *__variants__* inside our home directory. We will then move to this directory. This will be our new work directory.\n\n```bash\nmkdir ~/variants\ncd ~/variants\n```\n"])),(n()(),t.lb(54,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(55,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 5.2 Alignment Post-Processing\n\nBefore we do the actual variant calling procedure, we will first implement a series of steps to process the raw mapping output into a format readily usable for variant calling. The processing will be mostly done using the [PICARD](https://broadinstitute.github.io/picard/) toolkit. \n\n*__NOTE:__* In this exercise, we will call PICARD directly from the command line, with the command `picard`. However, in other systems, you may need to call PICARD through Java, *i.e.,* `java -jar picard.jar`.\n\nThe first step will be to *sort* the SAM file according to reference coordinates. By doing so, the subsequent algorithms will run more efficiently. At the same time, we will convert the output to BAM format, as we did before using SAMtools.\n\n```bash\npicard SortSam \\\nINPUT=~/mapping/alignment.sam \\\nOUTPUT=~/variants/alignment.sorted.bam \\\nSO=coordinate \\\nVALIDATION_STRINGENCY=SILENT\n```\n\nThe second step is to *mark duplicates*. In this sense, duplicates are reads that map to exactly the same region in the reference sequence. These reads most probably arise as artifacts of sequencing (e.g., optical duplicates, PCR duplicates) and are therefore deemed redundant. To avoid error amplification and miscalculation of coverage depth, duplicate reads must be handled properly in the subsequent steps.\n\n```bash\npicard MarkDuplicates \\\nINPUT=~/variants/alignment.sorted.bam \\\nOUTPUT=~/variants/alignment.mdup.bam \\\nMETRICS_FILE=~/variants/mdup.metrics \\\nASSUME_SORTED=TRUE \\\nVALIDATION_STRINGENCY=SILENT\n```\n\nThe third alignment post-processing step is the addition of *read groups*. This is not as crucial when dealing with a single sample, but is required by the variant caller to determine from which sequencing run the reads are from. This can be important when running variant calling for samples coming from multiple sequencing runs.\n\n```bash\npicard AddOrReplaceReadGroups \\\nINPUT=~/variants/alignment.mdup.bam \\\nOUTPUT=~/variants/alignment.rg.bam \\\nSO=coordinate \\\nRGID=lib1 RGLB=lib1 RGPL=Illumina RGPU=lib1 RGSM=lib1 \\\nVALIDATION_STRINGENCY=SILENT\n```\n\nThe fourth and final alignment post-processing step is to *index* the BAM file, which is required for variant calling later.\n```bash\npicard BuildBamIndex \\\nINPUT=~/variants/alignment.rg.bam\n```\n"])),(n()(),t.lb(57,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(58,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 5.3 Preparing the Reference\n\nSimilar to indexing the reference prior to read mapping, we also need to create a separate reference *fasta index* and *sequence dictionary* prior to variant calling. This is needed for the algorithm to run efficiently.\n\nTo create a reference sequence dictionary, we will also use PICARD.\n```bash\npicard CreateSequenceDictionary \\\nREFERENCE=~/data/ref/ecoli.fasta \\\nOUTPUT=~/data/ref/ecoli.dict\n```\n\nTo create the reference fasta index, we will use [SAMtools](http://samtools.sourceforge.net/).\n```bash\nsamtools faidx ~/data/ref/ecoli.fasta\n```\n"])),(n()(),t.lb(60,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(61,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 5.4 Variant Calling Proper\n\nWe will now peform the variant calling workflow using the [Genome Analysis Toolkit version 4 (GATK4)](https://software.broadinstitute.org/gatk/). \n\nWe can directly implement *variant calling* using GATK's HaplotypeCaller tool. This step will output a VCF file.\n```bash\ngatk HaplotypeCaller \\\n-R ~/data/ref/ecoli.fasta \\\n-I ~/variants/alignment.rg.bam \\\n-O ~/variants/variants.raw.vcf\n```\n\nIn cases where a set of *known variants* is available (also in VCF format), using the information from this variant database for *base quality score recalibration* is recommended. Since the sequencing reaction may introduce systematic biases in base quality scores, this step basically predicts covariances in base call qualities and generates a recalibration model to remove the observed biases -- thereby giving more accurate base call qualities. Note that the variant caller considers the quality of bases when deciding if a variant will be called. \n\nTo demonstrate, we will use the VCF file generated from the previous step as our set of known variants. We will now generate a recalibration model for the set of reads.\n```bash\ngatk BaseRecalibrator \\\n-R ~/data/ref/ecoli.fasta \\\n-I ~/variants/alignment.rg.bam \\\n-O ~/variants/recal.1.table \\\n-known-sites ~/variants/variants.raw.vcf\n```\n\nWe will then apply the recalibration model to generate a new BAM file with recalibrated base quality scores.\n```bash\ngatk ApplyBQSR \\\n-R ~/data/ref/ecoli.fasta \\\n-I ~/variants/alignment.rg.bam \\\n-O ~/variants/alignment.recal.bam \\\n-bqsr ~/variants/recal.1.table\n```\n\nJust to see if the previous model applied is good enough, we will run the recalibrator again on the recalibrated BAM file.\n```bash\ngatk BaseRecalibrator \\\n-R ~/data/ref/ecoli.fasta \\\n-I ~/variants/alignment.recal.bam \\\n-O ~/variants/recal.2.table \\\n-known-sites ~/variants/variants.raw.vcf\n```\n\nLet's check if the recalibration was able to improve base quality scores through plots.\n```bash\ngatk AnalyzeCovariates \\\n-before ~/variants/recal.1.table \\\n-after ~/variants/recal.2.table \\\n-plots recal.plot.pdf\n```\n\nUsing the alignment file with recalibrated base qualities, we will now refine the variant calls by doing the *final variant calling* step.\n```bash\ngatk HaplotypeCaller \\\n-R ~/data/ref/ecoli.fasta \\\n-I ~/variants/alignment.recal.bam \\\n-O ~/variants/variants.final.vcf\n```\n\nThe final output for variant calling is a VCF file.\n"])),(n()(),t.lb(63,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(64,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 5.5 Variant Annotation\n\nIn most cases, we also want to predict what features in the genome are affected by the variants and what impacts these particular changes will have. To do this, we will use the tool [SnpEff](http://snpeff.sourceforge.net/). \n\n```bash\nsnpEff ecoli ~/variants/variants.final.vcf > \\\n~/variants/variants.ann.vcf\n```\n\nThis step will output a VCF file with annotation fields.\n"])),(n()(),t.lb(66,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(67,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,['\n### 5.6 Visualization\n\nIn order for us to visualize the variants, we will use the tool [Tablet](https://ics.hutton.ac.uk/tablet/) to view the alignment and check for the variant positions.\n```bash\ntablet\n```\n\nA window will appear and we will open the alignment file from there.\n\n* Tablet -> Open Assembly\n    + Primary assembly file: `~/variants/alignment.recal.bam`\n    + Reference/consensus file: `~/data/ref/ecoli.fasta`\n    + Click "Open"\n\n\n**Guide Questions:**\n\n1. How many variants were called?\n2. How many predicted high impact mutations are there?\n3. Are there short insertions or deletions?\n4. What is the ratio of non-synonymous vs. synonymous mutations? What can you imply from this value?\n5. Were the variants called accurately? How can you tell?\n\n'])),(n()(),t.lb(69,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(70,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n## 6. Alternate Reference Assembly and Annotation\n"])),(n()(),t.lb(72,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(73,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,["\n### 6.1 Setting Up\n\nFirst, we will create the directory *__altref__* inside our home directory. We will then move to this directory. This will be our new work directory.\n```bash\nmkdir ~/altref\ncd ~/altref\n```\n\n"])),(n()(),t.lb(75,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(76,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(77,0,['\n### 6.2 Assembly and Annotation Proper\n\nFor this step, we will use [RGAAT](https://sourceforge.net/projects/rgaat/files/), which stands for Reference based Genome Assembly and Annotation Tool. This tool allows us to generate an alternate reference sequence -- reference sequence with the variant positions substituted with alternate alleles -- and transfer the reference annotations to the alternate reference sequence. \n```bash\nRGAAT.pl -g ~/data/ref/ecoli.fasta \\\n-a ~/data/ref/ecoli.gff \\\n-v ~/variants/variants.ann.vcf \\\n-o ~/altref/altref\n```\n\nThis step will output a number of files prefixed with the value under the `-o` parameter (in this case, *"altref"*). \n\nOutput File |   | Content Description\n------------|---|--------------------------------------\n`',"prefix",".anno_update` |   | updated annotation file (same format as the input annotation)\n`","prefix",".genome_update` |   | aternate reference sequence file in FASTA format\n`","prefix",".pos_change` |   | list of all the positions where changes have been made\n`*.vcf` |   | VCF file containing variants relative to the alternate assembly\n`","prefix","*.svg` |   | image file of the sequence with markers for the variant positions\n\n*__NOTE:__* Do not open the SVG file as it might cause the workstation to hang.\n"])),(n()(),t.lb(78,0,null,null,2,"markdown",[],null,null,null,r,o)),t.kb(79,4243456,null,0,s.a,[t.k,s.c],null,null),(n()(),t.vb(-1,0,['\n### 6.3 Visualization\n\nWe will now visulaize the alternate reference assembly using Tablet.\n```bash\ntablet\n```\n\nA window will appear and we will open the alignment file from there. However, this time around, instead of the reference fasta, we will use the alternate assembly as reference.\n\n* Tablet -> Open Assembly\n    + Primary assembly file: `~/variants/alignment.recal.bam`\n    + Reference/consensus file: `~/altref/altref.genome_update`\n    + Click "Open"\n\n\n**Guide Questions**\n\n1. How many positions differ between the reference sequence and the alternate reference assembly?\n2. Viewing the alignment using the alternate assembly as reference, are the variants still present?\n\n']))],null,function(n,e){n(e,77,0,"{","}","{","}","{","}","{","}")})}function m(n){return t.wb(0,[(n()(),t.lb(0,0,null,null,1,"app-main",[],null,null,null,d,c)),t.kb(1,114688,null,0,u,[],null,null)],function(n,e){n(e,1,0)},null)}var h=t.hb("app-main",u,m,{},{},[]),b=a("Ip0R"),f=a("ZYCi"),p=function(){return function(){}}();a.d(e,"MainModuleNgFactory",function(){return g});var g=t.ib(l,[],function(n){return t.qb([t.rb(512,t.j,t.Y,[[8,[i.a,h]],[3,t.j],t.x]),t.rb(4608,b.i,b.h,[t.u,[2,b.o]]),t.rb(1073742336,b.b,b.b,[]),t.rb(1073742336,f.o,f.o,[[2,f.u],[2,f.n]]),t.rb(1073742336,p,p,[]),t.rb(1073742336,s.b,s.b,[]),t.rb(1073742336,l,l,[]),t.rb(1024,f.l,function(){return[[{path:"",component:u}]]},[])])})}}]);